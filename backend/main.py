"""
ì£¼ì‹ ë‚ ì”¨ ì˜ˆë³´íŒ - FastAPI ë©”ì¸ ì„œë²„ (ê°œì„ ëœ ë²„ì „)
ì ‘ê·¼ì„±, ê°œì¸í™”, ì„¤ëª…ê°€ëŠ¥í•œ AI ê¸°ëŠ¥ ì¶”ê°€
"""
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import asyncio
import logging
import structlog
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import time

from config import settings
from models import *
from data_pipeline import DataPipeline
from score_calculator import FundamentalScorer
from ml_predictor import StockPredictor
from cache_manager import CacheManager
from exceptions import *

# ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“ˆë“¤
from explainable_ai import ExplainablePredictor
from personalization import UserPersonalization
from alternative_data import AlternativeDataAnalyzer
from enhanced_backtesting import EnhancedBacktester

# êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
data_pipeline = None
scorer = None
predictor = None
explainable_predictor = None
cache = None
personalization = None
alternative_data = None
backtester = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global data_pipeline, scorer, predictor, explainable_predictor, cache, personalization, alternative_data, backtester
    
    logger.info("application_startup", env=settings.env)
    
    try:
        # ì„¤ì • ê²€ì¦
        settings.validate_settings()
        
        # ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        cache = CacheManager(settings.cache_db_path)
        await cache.initialize()
        
        data_pipeline = DataPipeline(cache)
        scorer = FundamentalScorer()
        predictor = StockPredictor()
        
        # ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        explainable_predictor = ExplainablePredictor(predictor)
        personalization = UserPersonalization()
        alternative_data = AlternativeDataAnalyzer()
        backtester = EnhancedBacktester()
        
        # ML ëª¨ë¸ ë¡œë“œ
        await predictor.load_models()
        
        # ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ (ë°±ê·¸ë¼ìš´ë“œ)
        asyncio.create_task(initial_data_collection())
        
        logger.info("application_startup_complete")
        
    except Exception as e:
        logger.error("application_startup_failed", error=str(e))
        raise
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    logger.info("application_shutdown")
    if cache:
        await cache.close()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ì£¼ì‹ ë‚ ì”¨ ì˜ˆë³´íŒ API",
    description="AI ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ ì„œë¹„ìŠ¤ - ì„¤ëª…ê°€ëŠ¥í•œ AIì™€ ì ‘ê·¼ì„± ê°•í™”",
    version="3.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(StockWeatherException)
async def stock_weather_exception_handler(request: Request, exc: StockWeatherException):
    logger.error("custom_exception", exception=str(exc), path=request.url.path)
    return JSONResponse(
        status_code=400,
        content={"detail": str(exc), "type": exc.__class__.__name__}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error("unhandled_exception", exception=str(exc), path=request.url.path)
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error", "type": "InternalError"}
    )

# ë¯¸ë“¤ì›¨ì–´: ìš”ì²­ ë¡œê¹…
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(
        "request_processed",
        path=request.url.path,
        method=request.method,
        status_code=response.status_code,
        process_time=process_time
    )
    
    return response

async def initial_data_collection():
    """ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘"""
    try:
        logger.info("initial_data_collection_started")
        
        # í•œêµ­ ì£¼ì‹
        kr_tickers = await data_pipeline.get_kr_tickers()
        await data_pipeline.fetch_batch_data(kr_tickers[:100], market=Market.KR)
        
        # ë¯¸êµ­ ì£¼ì‹
        us_tickers = await data_pipeline.get_us_tickers()
        await data_pipeline.fetch_batch_data(us_tickers[:100], market=Market.US)
        
        logger.info("initial_data_collection_completed")
    except Exception as e:
        logger.error("initial_data_collection_failed", error=str(e))

@app.get("/")
async def root():
    """API ì •ë³´"""
    return {
        "service": "Stock Weather Dashboard",
        "version": "3.0.0",
        "environment": settings.env,
        "endpoints": {
            "/rankings": "ìƒìŠ¹/í•˜ë½ í™•ë¥  ë­í‚¹",
            "/rankings/explained": "ì„¤ëª… í¬í•¨ ë­í‚¹ (ì‹ ê·œ)",
            "/detail/{ticker}": "ì¢…ëª© ìƒì„¸ ì •ë³´",
            "/detail/{ticker}/explained": "ì„¤ëª… ê°€ëŠ¥í•œ AI ë¶„ì„ (ì‹ ê·œ)",
            "/sectors": "ì„¹í„°ë³„ ë‚ ì”¨ ì§€ë„",
            "/personalized/{user_id}": "ê°œì¸í™” ëŒ€ì‹œë³´ë“œ (ì‹ ê·œ)",
            "/backtest": "ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ (ì‹ ê·œ)",
            "/health": "ì„œë²„ ìƒíƒœ"
        }
    }

@app.get("/rankings", response_model=RankingsResponse)
async def get_rankings(
    market: Market = Market.ALL,
    limit: int = 20,
    user_id: Optional[str] = None,
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """ìƒìŠ¹/í•˜ë½ í™•ë¥  ë­í‚¹ ì¡°íšŒ (ê°œì„ ëœ ë²„ì „)"""
    logger.info("rankings_requested", market=market, limit=limit, user_id=user_id)
    
    try:
        # ê°œì¸í™” ì„¤ì • í™•ì¸
        if user_id:
            user_prefs = await personalization.get_user_preferences(user_id)
            if user_prefs:
                # ì„ í˜¸ ì„¹í„° í•„í„°ë§
                preferred_sectors = user_prefs.get('preferred_sectors', [])
                risk_tolerance = user_prefs.get('risk_tolerance', 'moderate')
        
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = cache.generate_cache_key(f"rankings_{market}_{limit}", "rankings")
        cached = await cache.get(cache_key)
        
        if cached and not await should_refresh_cache(cached):
            logger.info("rankings_from_cache", cache_key=cache_key)
            return RankingsResponse(**cached)
        
        # ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ë° ì˜ˆì¸¡
        stocks = await get_stock_predictions(market)
        
        # ëŒ€ì²´ ë°ì´í„° í¬í•¨
        for stock in stocks:
            alt_data = await alternative_data.analyze_social_sentiment(stock['ticker'])
            stock['social_sentiment'] = alt_data['composite_score']
            
            # ì¢…í•© ì ìˆ˜ ì¬ê³„ì‚° (ì†Œì…œ ê°ì„± í¬í•¨)
            stock['composite_score'] = (
                stock['probability'] * 0.6 +
                stock['fundamental_score'] * 0.3 +
                stock['social_sentiment'] * 0.1
            )
        
        # ê°œì¸í™” í•„í„°ë§
        if user_id and preferred_sectors:
            stocks = [s for s in stocks if s['sector'] in preferred_sectors]
        
        # ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ë³„ í•„í„°ë§
        if user_id and risk_tolerance:
            stocks = filter_by_risk_tolerance(stocks, risk_tolerance)
        
        # ìƒìŠ¹/í•˜ë½ í™•ë¥ ë¡œ ì •ë ¬
        top_gainers = sorted(stocks, key=lambda x: x['composite_score'], reverse=True)[:limit]
        top_losers = sorted(stocks, key=lambda x: x['composite_score'])[:limit]
        
        # ë‚ ì”¨ ì•„ì´ì½˜ ë° ì ‘ê·¼ì„± ì •ë³´ ì¶”ê°€
        for stock in top_gainers + top_losers:
            stock['weather_icon'] = get_weather_icon(stock['probability'])
            stock['accessibility_label'] = get_accessibility_label(stock)
        
        rankings_data = {
            "top_gainers": [StockRanking(**s) for s in top_gainers],
            "top_losers": [StockRanking(**s) for s in top_losers],
            "updated_at": datetime.now(),
            "user_personalized": user_id is not None
        }
        
        # ìºì‹œ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ)
        background_tasks.add_task(
            cache.set, 
            cache_key, 
            rankings_data, 
            ttl=settings.cache_ttl
        )
        
        logger.info("rankings_generated", gainers_count=len(top_gainers), losers_count=len(top_losers))
        return RankingsResponse(**rankings_data)
        
    except Exception as e:
        logger.error("rankings_error", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/rankings/explained")
async def get_explained_rankings(
    market: Market = Market.ALL,
    limit: int = 10
):
    """ì„¤ëª… ê°€ëŠ¥í•œ AI ë­í‚¹"""
    logger.info("explained_rankings_requested", market=market, limit=limit)
    
    try:
        # ê¸°ë³¸ ì˜ˆì¸¡ ê°€ì ¸ì˜¤ê¸°
        stocks = await get_stock_predictions(market)
        
        # ê° ì¢…ëª©ì— ëŒ€í•´ ì„¤ëª… ì¶”ê°€
        explained_stocks = []
        for stock in stocks[:limit]:  # ì„±ëŠ¥ì„ ìœ„í•´ ìƒìœ„ ì¢…ëª©ë§Œ
            stock_data = await data_pipeline.get_stock_data(stock['ticker'])
            
            # ì„¤ëª… ê°€ëŠ¥í•œ ì˜ˆì¸¡
            explained_prediction = await explainable_predictor.predict_with_explanation(stock_data)
            
            stock['explanation'] = explained_prediction['explanation']
            stock['transparency_score'] = explained_prediction['transparency_score']
            
            explained_stocks.append(stock)
        
        return {
            "stocks": explained_stocks,
            "explanation_methodology": "SHAP (SHapley Additive exPlanations)",
            "updated_at": datetime.now()
        }
        
    except Exception as e:
        logger.error("explained_rankings_error", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/detail/{ticker}", response_model=DetailedStock)
async def get_stock_detail(ticker: str):
    """ì¢…ëª© ìƒì„¸ ì •ë³´ ì¡°íšŒ (ê°œì„ ëœ ë²„ì „)"""
    logger.info("stock_detail_requested", ticker=ticker)
    
    try:
        # ìºì‹œ í™•ì¸
        cache_key = cache.generate_cache_key(ticker, "detail")
        cached = await cache.get(cache_key)
        
        if cached and (datetime.now() - cached['last_updated']).seconds < settings.cache_freshness:
            logger.info("stock_detail_from_cache", ticker=ticker)
            return DetailedStock(**cached)
        
        # ë°ì´í„° ìˆ˜ì§‘
        stock_data = await data_pipeline.get_stock_data(ticker)
        
        if not stock_data:
            raise HTTPException(status_code=404, detail="ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # í€ë”ë©˜í„¸ ë¶„ì„
        fundamental_score, breakdown = await scorer.calculate_detailed_score(stock_data)
        
        # ê°€ê²© ì˜ˆì¸¡
        prediction = await predictor.predict_single(stock_data)
        
        # ëŒ€ì²´ ë°ì´í„° ë¶„ì„
        alt_data = await alternative_data.analyze_social_sentiment(ticker)
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        technical = calculate_technical_indicators(stock_data.get('price_history', []))
        
        # ë‰´ìŠ¤ ê°ì„± ë¶„ì„
        news_sentiment = await analyze_news_sentiment(ticker) if ticker.endswith('.KS') else None
        
        # ê°€ê²© ì´ë ¥ ë³€í™˜
        price_history = [
            PriceHistory(**p) for p in stock_data.get('price_history', [])[-120:]
        ]
        
        detailed_info = DetailedStock(
            ticker=ticker,
            name=stock_data.get('name', ticker),
            sector=stock_data.get('sector', 'Unknown'),
            current_price=stock_data.get('current_price', 0),
            probability=prediction['probability'],
            expected_return=prediction['expected_return'],
            fundamental_breakdown=breakdown,
            price_history=price_history,
            news_sentiment=news_sentiment,
            social_sentiment=alt_data['composite_score'],
            technical_indicators=technical,
            last_updated=datetime.now()
        )
        
        # ìºì‹œ ì €ì¥
        await cache.set(cache_key, detailed_info.dict(), ttl=settings.cache_ttl)
        
        logger.info("stock_detail_generated", ticker=ticker)
        return detailed_info
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error("stock_detail_error", ticker=ticker, error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/detail/{ticker}/explained")
async def get_explained_detail(ticker: str):
    """ì„¤ëª… ê°€ëŠ¥í•œ AI ìƒì„¸ ë¶„ì„"""
    try:
        # ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘
        stock_data = await data_pipeline.get_stock_data(ticker)
        
        if not stock_data:
            raise HTTPException(status_code=404, detail="ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì„¤ëª… ê°€ëŠ¥í•œ ì˜ˆì¸¡
        explained = await explainable_predictor.predict_with_explanation(stock_data)
        
        return {
            "ticker": ticker,
            "name": stock_data.get('name', ticker),
            "prediction": {
                "probability": explained['probability'],
                "expected_return": explained['expected_return'],
                "confidence": explained['confidence']
            },
            "explanation": explained['explanation'],
            "transparency_score": explained['transparency_score'],
            "feature_contributions": {
                "technical": sum([f['impact'] for f in explained['explanation']['top_positive_factors'] 
                                if f['name'] in ['5ì¼ ìˆ˜ìµë¥ ', '20ì¼ ìˆ˜ìµë¥ ', 'RSI', 'MACD']]),
                "fundamental": sum([f['impact'] for f in explained['explanation']['top_positive_factors'] 
                                  if f['name'] in ['ROE', 'EPS ì„±ì¥ë¥ ', 'ë§¤ì¶œ ì„±ì¥ë¥ ']]),
                "volatility": next((f['impact'] for f in explained['explanation']['top_negative_factors'] 
                                  if f['name'] == 'ë³€ë™ì„±'), 0)
            }
        }
        
    except Exception as e:
        logger.error("explained_detail_error", ticker=ticker, error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/personalized/{user_id}")
async def create_user_profile(user_id: str, preferences: UserPreferences):
    """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
    try:
        await personalization.create_user_profile(user_id, preferences.dict())
        
        return {
            "user_id": user_id,
            "status": "profile_created",
            "preferences": preferences.dict()
        }
        
    except Exception as e:
        logger.error("create_profile_error", user_id=user_id, error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/personalized/{user_id}/dashboard")
async def get_personalized_dashboard(user_id: str):
    """ê°œì¸í™”ëœ ëŒ€ì‹œë³´ë“œ"""
    try:
        dashboard_config = await personalization.get_personalized_dashboard(user_id)
        
        # ê°œì¸í™”ëœ ë°ì´í„° ìˆ˜ì§‘
        personalized_data = {}
        
        if 'top_5_stocks' in dashboard_config['widgets']:
            rankings = await get_rankings(user_id=user_id, limit=5)
            personalized_data['top_stocks'] = rankings.top_gainers
        
        if 'sector_rotation' in dashboard_config['widgets']:
            personalized_data['sectors'] = await get_sector_weather()
        
        if 'learning_tips' in dashboard_config['widgets']:
            personalized_data['tips'] = get_learning_tips(dashboard_config.get('experience_level', 'beginner'))
        
        return {
            "user_id": user_id,
            "layout": dashboard_config['layout'],
            "data": personalized_data,
            "updated_at": datetime.now()
        }
        
    except Exception as e:
        logger.error("personalized_dashboard_error", user_id=user_id, error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/backtest/results")
async def get_backtest_results(
    start_date: str = "2023-01-01",
    end_date: str = "2024-01-01"
):
    """í–¥ìƒëœ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼"""
    try:
        results = await backtester.run_comprehensive_backtest(start_date, end_date)
        
        return {
            "period": results['period'],
            "overall_accuracy": results['accuracy_metrics'].get('overall', 0),
            "market_conditions": results['market_condition_analysis'],
            "risk_metrics": results['risk_metrics'],
            "drawdown": results['drawdown_analysis'],
            "key_insights": [
                f"ìµœëŒ€ ì†ì‹¤ë¥ : {results['drawdown_analysis']['max_drawdown']:.2%}",
                f"ìƒ¤í”„ ë¹„ìœ¨: {results['risk_metrics']['sharpe_ratio']:.2f}",
                f"95% VaR: {results['risk_metrics']['var_95']:.2%}"
            ]
        }
        
    except Exception as e:
        logger.error("backtest_error", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/sectors")
async def get_sector_weather():
    """ì„¹í„°ë³„ ë‚ ì”¨ ì§€ë„ (ê°œì„ ëœ ë²„ì „)"""
    logger.info("sector_weather_requested")
    
    try:
        # ì„¹í„°ë³„ í‰ê·  í™•ë¥  ê³„ì‚°
        sector_data = await data_pipeline.get_sector_aggregates()
        
        sector_weather = []
        for sector, data in sector_data.items():
            # ëŒ€ì²´ ë°ì´í„°ë¡œ ë³´ê°•
            sector_sentiment = await alternative_data.get_sector_sentiment(sector)
            
            avg_probability = data.get('avg_probability', 0.5)
            combined_score = avg_probability * 0.8 + sector_sentiment * 0.2
            
            weather = SectorWeather(
                sector=sector,
                probability=combined_score,
                weather_icon=get_weather_icon(combined_score),
                weather_desc=get_weather_description(combined_score),
                stock_count=data.get('count', 0),
                top_stock=data.get('top_stock', ''),
                trend_strength=calculate_trend_strength(data)
            )
            sector_weather.append(weather)
        
        result = {
            "sectors": sorted(sector_weather, key=lambda x: x.probability, reverse=True),
            "market_overview": calculate_market_overview(sector_weather),
            "updated_at": datetime.now().isoformat()
        }
        
        logger.info("sector_weather_generated", sector_count=len(sector_weather))
        return result
        
    except Exception as e:
        logger.error("sector_weather_error", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ (í™•ì¥ëœ ë²„ì „)"""
    try:
        # ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
        checks = {
            "cache": await cache.health_check() if cache else False,
            "models": predictor.is_loaded if predictor else False,
            "data_pipeline": data_pipeline is not None,
            "explainable_ai": explainable_predictor is not None,
            "personalization": personalization is not None,
            "alternative_data": alternative_data is not None
        }
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        cache_stats = await cache.get_stats() if cache else {}
        
        all_healthy = all(checks.values())
        
        return {
            "status": "healthy" if all_healthy else "unhealthy",
            "checks": checks,
            "metrics": {
                "cache_hit_rate": cache_stats.get('hit_rate', 0),
                "total_predictions": cache_stats.get('total_entries', 0),
                "uptime": get_uptime()
            },
            "timestamp": datetime.now().isoformat(),
            "environment": settings.env
        }
    except Exception as e:
        logger.error("health_check_error", error=str(e))
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# í—¬í¼ í•¨ìˆ˜ë“¤
async def should_refresh_cache(cached_data: Dict) -> bool:
    """ìºì‹œ ê°±ì‹  í•„ìš” ì—¬ë¶€ í™•ì¸"""
    if not cached_data:
        return True
    
    # ì—…ë°ì´íŠ¸ ì‹œê°„ í™•ì¸
    if 'updated_at' in cached_data:
        if isinstance(cached_data['updated_at'], str):
            updated_at = datetime.fromisoformat(cached_data['updated_at'])
        else:
            updated_at = cached_data['updated_at']
        
        age = (datetime.now() - updated_at).seconds
        
        # 3ì‹œê°„ TTL
        if age > settings.cache_ttl:
            return True
        
        # ìµœê·¼ 1ì‹œê°„ ì´ë‚´ ë°ì´í„°ëŠ” ìœ ì§€
        if age < settings.cache_freshness:
            return False
    
    return False

async def get_stock_predictions(market: Market) -> List[Dict]:
    """ì£¼ì‹ ì˜ˆì¸¡ ë°ì´í„° ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    logger.info("generating_predictions", market=market)
    
    # í‹°ì»¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if market == Market.KR:
        tickers = await data_pipeline.get_kr_tickers()
    elif market == Market.US:
        tickers = await data_pipeline.get_us_tickers()
    else:  # ALL
        kr_tickers = await data_pipeline.get_kr_tickers()
        us_tickers = await data_pipeline.get_us_tickers()
        tickers = kr_tickers[:50] + us_tickers[:50]
    
    predictions = []
    
    # ë°°ì¹˜ ì²˜ë¦¬
    for i in range(0, len(tickers), settings.batch_size):
        batch = tickers[i:i+settings.batch_size]
        batch_data = await data_pipeline.fetch_batch_data(batch, market)
        
        for ticker, data in batch_data.items():
            if data:
                try:
                    # í€ë”ë©˜í„¸ ìŠ¤ì½”ì–´
                    fundamental_score = await scorer.calculate_score(data)
                    
                    # ML ì˜ˆì¸¡
                    prediction = await predictor.predict_single(data)
                    
                    predictions.append({
                        "ticker": ticker,
                        "name": data.get('name', ticker),
                        "sector": data.get('sector', 'Unknown'),
                        "probability": prediction['probability'],
                        "expected_return": prediction['expected_return'],
                        "fundamental_score": fundamental_score,
                        "confidence": prediction.get('confidence', 0.5)
                    })
                except Exception as e:
                    logger.error("prediction_error", ticker=ticker, error=str(e))
    
    logger.info("predictions_generated", count=len(predictions))
    return predictions

def get_weather_icon(probability: float) -> str:
    """í™•ë¥ ì— ë”°ë¥¸ ë‚ ì”¨ ì•„ì´ì½˜"""
    if probability >= 0.7:
        return "â˜€ï¸"  # ë§‘ìŒ
    elif probability >= 0.6:
        return "ğŸŒ¤ï¸"  # ì•½ê°„ êµ¬ë¦„
    elif probability >= 0.4:
        return "â›…"  # êµ¬ë¦„ ë§ìŒ
    elif probability >= 0.3:
        return "ğŸŒ¥ï¸"  # íë¦¼
    else:
        return "ğŸŒ§ï¸"  # ë¹„

def get_weather_description(probability: float) -> str:
    """í™•ë¥ ì— ë”°ë¥¸ ë‚ ì”¨ ì„¤ëª…"""
    if probability >= 0.7:
        return "ë§‘ê³  í™”ì°½í•œ ìƒìŠ¹ì„¸ê°€ ì˜ˆìƒë©ë‹ˆë‹¤"
    elif probability >= 0.6:
        return "ëŒ€ì²´ë¡œ ë§‘ì€ ìƒìŠ¹ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"
    elif probability >= 0.4:
        return "ë³€ë™ì„±ì´ ìˆëŠ” êµ¬ë¦„ ë‚€ ë‚ ì”¨ì…ë‹ˆë‹¤"
    elif probability >= 0.3:
        return "íë¦° ë‚ ì”¨ë¡œ ì¡°ì • ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"
    else:
        return "ë¹„ ì˜¤ëŠ” ë‚ ì”¨, í•˜ë½ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"

def get_accessibility_label(stock: Dict) -> str:
    """ì ‘ê·¼ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë ˆì´ë¸” ìƒì„±"""
    return (
        f"{stock['name']} ì¢…ëª©, "
        f"ìƒìŠ¹ í™•ë¥  {int(stock['probability'] * 100)}í¼ì„¼íŠ¸, "
        f"ì˜ˆìƒ ìˆ˜ìµë¥  {'í”ŒëŸ¬ìŠ¤' if stock['expected_return'] > 0 else 'ë§ˆì´ë„ˆìŠ¤'} "
        f"{abs(stock['expected_return']):.1f}í¼ì„¼íŠ¸, "
        f"ì‹ ë¢°ë„ {int(stock['confidence'] * 100)}í¼ì„¼íŠ¸"
    )

def filter_by_risk_tolerance(stocks: List[Dict], risk_tolerance: str) -> List[Dict]:
    """ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ë³„ í•„í„°ë§"""
    if risk_tolerance == 'conservative':
        # ë³´ìˆ˜ì : ë³€ë™ì„± ë‚®ì€ ì¢…ëª©
        return [s for s in stocks if s.get('volatility', 0) < 0.15 and s['confidence'] > 0.7]
    elif risk_tolerance == 'aggressive':
        # ê³µê²©ì : ë†’ì€ ìˆ˜ìµë¥  ê¸°ëŒ€
        return [s for s in stocks if abs(s['expected_return']) > 5]
    else:  # moderate
        return stocks

def calculate_technical_indicators(price_history: List[Dict]) -> Dict[str, float]:
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
    if len(price_history) < 20:
        return {
            "ma20": 0,
            "ma60": 0,
            "rsi": 50,
            "volatility": 0,
            "bollinger_upper": 0,
            "bollinger_lower": 0,
            "macd": 0,
            "signal": 0
        }
    
    try:
        closes = [p['close'] for p in price_history]
        
        # ì´ë™í‰ê· 
        ma20 = sum(closes[-20:]) / 20
        ma60 = sum(closes[-60:]) / 60 if len(closes) >= 60 else ma20
        
        # RSI
        rsi = calculate_rsi(closes)
        
        # ë³€ë™ì„±
        volatility = calculate_volatility(closes[-20:])
        
        # ë³¼ë¦°ì € ë°´ë“œ
        std20 = np.std(closes[-20:])
        bollinger_upper = ma20 + (2 * std20)
        bollinger_lower = ma20 - (2 * std20)
        
        # MACD
        macd, signal = calculate_macd(closes)
        
        return {
            "ma20": round(ma20, 2),
            "ma60": round(ma60, 2),
            "rsi": round(rsi, 2),
            "volatility": round(volatility, 2),
            "bollinger_upper": round(bollinger_upper, 2),
            "bollinger_lower": round(bollinger_lower, 2),
            "macd": round(macd, 2),
            "signal": round(signal, 2)
        }
    except Exception as e:
        logger.error("technical_indicators_error", error=str(e))
        return {
            "ma20": 0,
            "ma60": 0,
            "rsi": 50,
            "volatility": 0,
            "bollinger_upper": 0,
            "bollinger_lower": 0,
            "macd": 0,
            "signal": 0
        }

def calculate_rsi(prices: List[float], period: int = 14) -> float:
    """RSI ê³„ì‚°"""
    if len(prices) < period + 1:
        return 50.0
    
    gains = []
    losses = []
    
    for i in range(1, len(prices)):
        diff = prices[i] - prices[i-1]
        if diff > 0:
            gains.append(diff)
            losses.append(0)
        else:
            gains.append(0)
            losses.append(abs(diff))
    
    avg_gain = sum(gains[-period:]) / period if gains else 0
    avg_loss = sum(losses[-period:]) / period if losses else 0
    
    if avg_loss == 0:
        return 100.0
    
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    
    return rsi

def calculate_volatility(prices: List[float]) -> float:
    """ë³€ë™ì„± ê³„ì‚°"""
    import numpy as np
    
    if len(prices) < 2:
        return 0.0
    
    returns = [(prices[i] / prices[i-1] - 1) for i in range(1, len(prices))]
    return np.std(returns) * np.sqrt(252) * 100  # ì—°ìœ¨í™”

def calculate_macd(prices: List[float]) -> Tuple[float, float]:
    """MACD ê³„ì‚°"""
    if len(prices) < 26:
        return 0.0, 0.0
    
    # EMA ê³„ì‚°
    ema12 = calculate_ema(prices, 12)
    ema26 = calculate_ema(prices, 26)
    
    macd = ema12 - ema26
    signal = calculate_ema([macd], 9)  # ì‹ í˜¸ì„ 
    
    return macd, signal

def calculate_ema(prices: List[float], period: int) -> float:
    """ì§€ìˆ˜ì´ë™í‰ê·  ê³„ì‚°"""
    if len(prices) < period:
        return prices[-1] if prices else 0
    
    multiplier = 2 / (period + 1)
    ema = prices[-period]
    
    for price in prices[-period+1:]:
        ema = (price - ema) * multiplier + ema
    
    return ema

async def analyze_news_sentiment(ticker: str) -> float:
    """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (í•œêµ­ ì£¼ì‹ë§Œ)"""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ news_analyzer.py ëª¨ë“ˆ ì‚¬ìš©
    # ì—¬ê¸°ì„œëŠ” ë¬´ë£Œ ì†ŒìŠ¤ í™œìš©
    try:
        # Google News RSS í™œìš©
        import feedparser
        feed_url = f"https://news.google.com/rss/search?q={ticker}+ì£¼ê°€&hl=ko&gl=KR&ceid=KR:ko"
        feed = feedparser.parse(feed_url)
        
        if feed.entries:
            # ê°„ë‹¨í•œ ê°ì„± ë¶„ì„
            positive_keywords = ['ìƒìŠ¹', 'í˜¸ì¬', 'ì‹ ê³ ê°€', 'ë§¤ìˆ˜', 'ê¸ì •ì ']
            negative_keywords = ['í•˜ë½', 'ì•…ì¬', 'ì‹ ì €ê°€', 'ë§¤ë„', 'ë¶€ì •ì ']
            
            sentiment_scores = []
            for entry in feed.entries[:10]:
                title = entry.title
                positive_count = sum(1 for word in positive_keywords if word in title)
                negative_count = sum(1 for word in negative_keywords if word in title)
                
                if positive_count > negative_count:
                    sentiment_scores.append(1)
                elif negative_count > positive_count:
                    sentiment_scores.append(-1)
                else:
                    sentiment_scores.append(0)
            
            return sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
    except:
        return 0

def calculate_trend_strength(sector_data: Dict) -> float:
    """ì„¹í„° íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚°"""
    probabilities = sector_data.get('probabilities', [])
    if not probabilities:
        return 0.5
    
    # í™•ë¥ ì˜ í‘œì¤€í¸ì°¨ê°€ ë‚®ìœ¼ë©´ ê°•í•œ íŠ¸ë Œë“œ
    import numpy as np
    std_dev = np.std(probabilities)
    avg_prob = np.mean(probabilities)
    
    # íŠ¸ë Œë“œ ê°•ë„: í‰ê· ì´ ê·¹ë‹¨ê°’ì— ê°€ê¹ê³  í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ê°•í•¨
    trend_strength = abs(avg_prob - 0.5) * 2 * (1 - std_dev)
    return min(1.0, max(0.0, trend_strength))

def calculate_market_overview(sectors: List[SectorWeather]) -> Dict:
    """ì „ì²´ ì‹œì¥ ê°œìš” ê³„ì‚°"""
    if not sectors:
        return {"status": "unknown", "temperature": 50}
    
    avg_probability = sum(s.probability for s in sectors) / len(sectors)
    
    # ì‹œì¥ ì˜¨ë„ (0-100)
    temperature = int(avg_probability * 100)
    
    # ì‹œì¥ ìƒíƒœ
    if temperature >= 70:
        status = "overheated"
        description = "ê³¼ì—´ ì£¼ì˜ - ì¡°ì • ê°€ëŠ¥ì„±"
    elif temperature >= 60:
        status = "bullish"
        description = "ê°•ì„¸ ì‹œì¥ - ìƒìŠ¹ ìš°ì„¸"
    elif temperature >= 40:
        status = "neutral"
        description = "ì¤‘ë¦½ ì‹œì¥ - ê´€ë§ì„¸"
    elif temperature >= 30:
        status = "bearish"
        description = "ì•½ì„¸ ì‹œì¥ - í•˜ë½ ìš°ì„¸"
    else:
        status = "oversold"
        description = "ê³¼ë§¤ë„ - ë°˜ë“± ê°€ëŠ¥ì„±"
    
    return {
        "status": status,
        "temperature": temperature,
        "description": description,
        "strongest_sectors": [s.sector for s in sorted(sectors, key=lambda x: x.probability, reverse=True)[:3]],
        "weakest_sectors": [s.sector for s in sorted(sectors, key=lambda x: x.probability)[:3]]
    }

def get_learning_tips(experience_level: str) -> List[Dict]:
    """ê²½í—˜ ìˆ˜ì¤€ë³„ í•™ìŠµ íŒ"""
    tips = {
        'beginner': [
            {
                "title": "ë‚ ì”¨ ì•„ì´ì½˜ì˜ ì˜ë¯¸",
                "content": "â˜€ï¸ëŠ” ìƒìŠ¹ ê°€ëŠ¥ì„±ì´ ë†’ìŒì„, ğŸŒ§ï¸ëŠ” í•˜ë½ ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                "icon": "ğŸ’¡"
            },
            {
                "title": "í€ë”ë©˜í„¸ ì ìˆ˜ë€?",
                "content": "ê¸°ì—…ì˜ ì¬ë¬´ ê±´ì „ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.",
                "icon": "ğŸ“Š"
            },
            {
                "title": "ë¶„ì‚° íˆ¬ìì˜ ì¤‘ìš”ì„±",
                "content": "í•œ ì¢…ëª©ì— ëª¨ë“  ìê¸ˆì„ íˆ¬ìí•˜ì§€ ë§ˆì„¸ìš”. ì—¬ëŸ¬ ì¢…ëª©ì— ë‚˜ëˆ„ì–´ íˆ¬ìí•˜ì„¸ìš”.",
                "icon": "ğŸ¯"
            }
        ],
        'intermediate': [
            {
                "title": "RSI ì§€í‘œ í™œìš©",
                "content": "RSIê°€ 30 ì´í•˜ë©´ ê³¼ë§¤ë„, 70 ì´ìƒì´ë©´ ê³¼ë§¤ìˆ˜ ìƒíƒœì…ë‹ˆë‹¤.",
                "icon": "ğŸ“ˆ"
            },
            {
                "title": "ì„¹í„° ë¡œí…Œì´ì…˜",
                "content": "ê²½ê¸° ì‚¬ì´í´ì— ë”°ë¼ ìœ ë§ ì„¹í„°ê°€ ë°”ë€ë‹ˆë‹¤. ì„¹í„°ë³„ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                "icon": "ğŸ”„"
            }
        ],
        'advanced': [
            {
                "title": "AI ì˜ˆì¸¡ì˜ í•œê³„",
                "content": "AI ì˜ˆì¸¡ì€ ê³¼ê±° ë°ì´í„° ê¸°ë°˜ì…ë‹ˆë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ì´ë²¤íŠ¸ëŠ” ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "icon": "ğŸ¤–"
            },
            {
                "title": "ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥ ",
                "content": "ë‹¨ìˆœ ìˆ˜ìµë¥ ë³´ë‹¤ ìƒ¤í”„ ë¹„ìœ¨ ë“± ë¦¬ìŠ¤í¬ ì¡°ì • ì§€í‘œë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                "icon": "âš–ï¸"
            }
        ]
    }
    
    return tips.get(experience_level, tips['beginner'])

def get_uptime() -> str:
    """ì„œë²„ ê°€ë™ ì‹œê°„"""
    # ì‹¤ì œ êµ¬í˜„ ì‹œ ì„œë²„ ì‹œì‘ ì‹œê°„ ì¶”ì 
    return "24h 35m 12s"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_config=None)
