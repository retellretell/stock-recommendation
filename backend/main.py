"""
ì£¼ì‹ ë‚ ì”¨ ì˜ˆë³´íŒ - FastAPI ë©”ì¸ ì„œë²„
"""
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import asyncio
import logging
import os
from dotenv import load_dotenv

from data_pipeline import DataPipeline
from score_calculator import FundamentalScorer
from ml_predictor import StockPredictor
from cache_manager import CacheManager

# í™˜ê²½ ì„¤ì •
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ì£¼ì‹ ë‚ ì”¨ ì˜ˆë³´íŒ API",
    description="AI ê¸°ë°˜ ì£¼ì‹ ìƒìŠ¹/í•˜ë½ í™•ë¥  ì˜ˆì¸¡ ì„œë¹„ìŠ¤",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
data_pipeline = DataPipeline()
scorer = FundamentalScorer()
predictor = StockPredictor()
cache = CacheManager()

# ë°ì´í„° ëª¨ë¸
class StockRanking(BaseModel):
    ticker: str
    name: str
    sector: str
    probability: float
    expected_return: float
    fundamental_score: float
    weather_icon: str
    confidence: float

class DetailedStock(BaseModel):
    ticker: str
    name: str
    sector: str
    current_price: float
    probability: float
    expected_return: float
    fundamental_breakdown: Dict[str, float]
    price_history: List[Dict[str, float]]
    news_sentiment: Optional[float]
    technical_indicators: Dict[str, float]
    last_updated: datetime

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    logger.info("ì£¼ì‹ ë‚ ì”¨ ì˜ˆë³´íŒ ì„œë²„ ì‹œì‘...")
    
    # ìºì‹œ ì´ˆê¸°í™”
    await cache.initialize()
    
    # ML ëª¨ë¸ ë¡œë“œ
    await predictor.load_models()
    
    # ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ (ë°±ê·¸ë¼ìš´ë“œ)
    asyncio.create_task(initial_data_collection())

async def initial_data_collection():
    """ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘"""
    try:
        # í•œêµ­ ì£¼ì‹
        kr_tickers = await data_pipeline.get_kr_tickers()
        await data_pipeline.fetch_batch_data(kr_tickers[:100], market='KR')
        
        # ë¯¸êµ­ ì£¼ì‹
        us_tickers = await data_pipeline.get_us_tickers()
        await data_pipeline.fetch_batch_data(us_tickers[:100], market='US')
        
        logger.info("ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

@app.get("/")
async def root():
    """API ì •ë³´"""
    return {
        "service": "Stock Weather Dashboard",
        "version": "1.0.0",
        "endpoints": {
            "/rankings": "ìƒìŠ¹/í•˜ë½ í™•ë¥  ë­í‚¹",
            "/detail/{ticker}": "ì¢…ëª© ìƒì„¸ ì •ë³´",
            "/sectors": "ì„¹í„°ë³„ ë‚ ì”¨ ì§€ë„",
            "/health": "ì„œë²„ ìƒíƒœ"
        }
    }

@app.get("/rankings", response_model=Dict[str, List[StockRanking]])
async def get_rankings(
    market: str = "ALL",
    limit: int = 20,
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """ìƒìŠ¹/í•˜ë½ í™•ë¥  ë­í‚¹ ì¡°íšŒ"""
    try:
        # ìºì‹œ í™•ì¸
        cache_key = f"rankings_{market}_{limit}"
        cached = await cache.get(cache_key)
        
        if cached and not await should_refresh_cache(cached):
            return cached
        
        # ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ë° ì˜ˆì¸¡
        stocks = await get_stock_predictions(market)
        
        # ìƒìŠ¹/í•˜ë½ í™•ë¥ ë¡œ ì •ë ¬
        top_gainers = sorted(stocks, key=lambda x: x['probability'], reverse=True)[:limit]
        top_losers = sorted(stocks, key=lambda x: x['probability'])[:limit]
        
        # ë‚ ì”¨ ì•„ì´ì½˜ ì¶”ê°€
        for stock in top_gainers + top_losers:
            stock['weather_icon'] = get_weather_icon(stock['probability'])
        
        rankings = {
            "top_gainers": [StockRanking(**s) for s in top_gainers],
            "top_losers": [StockRanking(**s) for s in top_losers],
            "updated_at": datetime.now().isoformat()
        }
        
        # ìºì‹œ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ)
        background_tasks.add_task(cache.set, cache_key, rankings, ttl=3600)
        
        return rankings
        
    except Exception as e:
        logger.error(f"ë­í‚¹ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/detail/{ticker}", response_model=DetailedStock)
async def get_stock_detail(ticker: str):
    """ì¢…ëª© ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        # ìºì‹œ í™•ì¸
        cache_key = f"detail_{ticker}"
        cached = await cache.get(cache_key)
        
        if cached and (datetime.now() - cached['last_updated']).seconds < 3600:
            return DetailedStock(**cached)
        
        # ë°ì´í„° ìˆ˜ì§‘
        stock_data = await data_pipeline.get_stock_data(ticker)
        
        if not stock_data:
            raise HTTPException(status_code=404, detail="ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # í€ë”ë©˜í„¸ ë¶„ì„
        fundamental_score, breakdown = await scorer.calculate_detailed_score(stock_data)
        
        # ê°€ê²© ì˜ˆì¸¡
        prediction = await predictor.predict_single(stock_data)
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        technical = calculate_technical_indicators(stock_data['price_history'])
        
        # ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (ì˜µì…˜)
        news_sentiment = await analyze_news_sentiment(ticker) if ticker.endswith('.KS') else None
        
        detailed_info = {
            "ticker": ticker,
            "name": stock_data['name'],
            "sector": stock_data['sector'],
            "current_price": stock_data['current_price'],
            "probability": prediction['probability'],
            "expected_return": prediction['expected_return'],
            "fundamental_breakdown": breakdown,
            "price_history": stock_data['price_history'][-120:],  # ìµœê·¼ 120ì¼
            "news_sentiment": news_sentiment,
            "technical_indicators": technical,
            "last_updated": datetime.now()
        }
        
        # ìºì‹œ ì €ì¥
        await cache.set(cache_key, detailed_info, ttl=3600)
        
        return DetailedStock(**detailed_info)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜ {ticker}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/sectors")
async def get_sector_weather():
    """ì„¹í„°ë³„ ë‚ ì”¨ ì§€ë„"""
    try:
        # ì„¹í„°ë³„ í‰ê·  í™•ë¥  ê³„ì‚°
        sector_data = await data_pipeline.get_sector_aggregates()
        
        sector_weather = []
        for sector, data in sector_data.items():
            avg_probability = data['avg_probability']
            weather = {
                "sector": sector,
                "probability": avg_probability,
                "weather_icon": get_weather_icon(avg_probability),
                "weather_desc": get_weather_description(avg_probability),
                "stock_count": data['count'],
                "top_stock": data['top_stock']
            }
            sector_weather.append(weather)
        
        return {
            "sectors": sorted(sector_weather, key=lambda x: x['probability'], reverse=True),
            "updated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì„¹í„° ë‚ ì”¨ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        # ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
        cache_status = await cache.health_check()
        model_status = predictor.is_loaded
        
        return {
            "status": "healthy" if cache_status and model_status else "unhealthy",
            "cache": "ok" if cache_status else "error",
            "models": "loaded" if model_status else "not loaded",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# í—¬í¼ í•¨ìˆ˜ë“¤
async def should_refresh_cache(cached_data: Dict) -> bool:
    """ìºì‹œ ê°±ì‹  í•„ìš” ì—¬ë¶€ í™•ì¸"""
    if not cached_data:
        return True
    
    # 3ì‹œê°„ TTL
    if 'updated_at' in cached_data:
        age = (datetime.now() - datetime.fromisoformat(cached_data['updated_at'])).seconds
        if age > 10800:  # 3ì‹œê°„
            return True
    
    # ìµœê·¼ 1ì‹œê°„ ì´ë‚´ ë°ì´í„°ëŠ” ìœ ì§€
    if age < 3600:
        return False
    
    # Â±5% ë³€ë™ ì²´í¬ (êµ¬í˜„ í•„ìš”)
    # TODO: ì‹¤ì‹œê°„ ê°€ê²©ê³¼ ë¹„êµí•˜ì—¬ í° ë³€ë™ì´ ìˆìœ¼ë©´ True
    
    return False

async def get_stock_predictions(market: str) -> List[Dict]:
    """ì£¼ì‹ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±"""
    # í‹°ì»¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    if market == "KR":
        tickers = await data_pipeline.get_kr_tickers()
    elif market == "US":
        tickers = await data_pipeline.get_us_tickers()
    else:  # ALL
        kr_tickers = await data_pipeline.get_kr_tickers()
        us_tickers = await data_pipeline.get_us_tickers()
        tickers = kr_tickers[:50] + us_tickers[:50]
    
    predictions = []
    
    # ë°°ì¹˜ ì²˜ë¦¬
    for i in range(0, len(tickers), 100):
        batch = tickers[i:i+100]
        batch_data = await data_pipeline.fetch_batch_data(batch, market)
        
        for ticker, data in batch_data.items():
            if data:
                # í€ë”ë©˜í„¸ ìŠ¤ì½”ì–´
                fundamental_score = await scorer.calculate_score(data)
                
                # ML ì˜ˆì¸¡
                prediction = await predictor.predict_single(data)
                
                predictions.append({
                    "ticker": ticker,
                    "name": data.get('name', ticker),
                    "sector": data.get('sector', 'Unknown'),
                    "probability": prediction['probability'],
                    "expected_return": prediction['expected_return'],
                    "fundamental_score": fundamental_score,
                    "confidence": prediction.get('confidence', 0.5)
                })
    
    return predictions

def get_weather_icon(probability: float) -> str:
    """í™•ë¥ ì— ë”°ë¥¸ ë‚ ì”¨ ì•„ì´ì½˜"""
    if probability >= 0.7:
        return "â˜€ï¸"  # ë§‘ìŒ
    elif probability >= 0.6:
        return "ğŸŒ¤ï¸"  # ì•½ê°„ êµ¬ë¦„
    elif probability >= 0.4:
        return "â›…"  # êµ¬ë¦„ ë§ìŒ
    elif probability >= 0.3:
        return "ğŸŒ¥ï¸"  # íë¦¼
    else:
        return "ğŸŒ§ï¸"  # ë¹„

def get_weather_description(probability: float) -> str:
    """í™•ë¥ ì— ë”°ë¥¸ ë‚ ì”¨ ì„¤ëª…"""
    if probability >= 0.7:
        return "ë§‘ê³  í™”ì°½í•œ ìƒìŠ¹ì„¸ê°€ ì˜ˆìƒë©ë‹ˆë‹¤"
    elif probability >= 0.6:
        return "ëŒ€ì²´ë¡œ ë§‘ì€ ìƒìŠ¹ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"
    elif probability >= 0.4:
        return "ë³€ë™ì„±ì´ ìˆëŠ” êµ¬ë¦„ ë‚€ ë‚ ì”¨ì…ë‹ˆë‹¤"
    elif probability >= 0.3:
        return "íë¦° ë‚ ì”¨ë¡œ ì¡°ì • ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"
    else:
        return "ë¹„ ì˜¤ëŠ” ë‚ ì”¨, í•˜ë½ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"

def calculate_technical_indicators(price_history: List[Dict]) -> Dict[str, float]:
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    if len(price_history) < 20:
        return {}
    
    closes = [p['close'] for p in price_history]
    
    # ì´ë™í‰ê· 
    ma20 = sum(closes[-20:]) / 20
    ma60 = sum(closes[-60:]) / 60 if len(closes) >= 60 else ma20
    
    # RSI
    gains = []
    losses = []
    for i in range(1, len(closes)):
        diff = closes[i] - closes[i-1]
        if diff > 0:
            gains.append(diff)
            losses.append(0)
        else:
            gains.append(0)
            losses.append(abs(diff))
    
    avg_gain = sum(gains[-14:]) / 14 if gains else 0
    avg_loss = sum(losses[-14:]) / 14 if losses else 0
    rs = avg_gain / avg_loss if avg_loss > 0 else 100
    rsi = 100 - (100 / (1 + rs))
    
    return {
        "ma20": ma20,
        "ma60": ma60,
        "rsi": rsi,
        "volatility": calculate_volatility(closes[-20:])
    }

def calculate_volatility(prices: List[float]) -> float:
    """ë³€ë™ì„± ê³„ì‚°"""
    import numpy as np
    returns = [(prices[i] / prices[i-1] - 1) for i in range(1, len(prices))]
    return np.std(returns) * np.sqrt(252) * 100  # ì—°ìœ¨í™”

async def analyze_news_sentiment(ticker: str) -> float:
    """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (í•œêµ­ ì£¼ì‹ë§Œ)"""
    # TODO: ì‹¤ì œ êµ¬í˜„ ì‹œ news_analyzer.py ëª¨ë“ˆ ì‚¬ìš©
    # ì„ì‹œë¡œ ëœë¤ ê°’ ë°˜í™˜
    import random
    return random.uniform(-1, 1)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
